#!/usr/bin/env python3
# -*- coding:utf8 -*-
import sys

import numpy as np
import pandas as pd
import math

from processor.stanza_process import StanzaProcessor
from ans.how_what_why_answer import HowWhatWhyAnswer
from ans.who_when_where_answer import WhoWhenWhereAnswer
from ans.yes_no_answer import YesNoAnswer

class Answer:
    def __init__(self, article, questions):
        self.questions = questions
        self.article = open(article).read()
        self.answers = []
        self.tfidf = {}
        self.wordDict = {}
        

    def calculate_tfidf(self, article):
        # using tf-idf
        # Define data and preprocessing
        bow = article.split(" ")
        wordSet = set(bow)

        # Counting the number of words
        self.wordDict = dict.fromkeys(wordSet, 0)
        for word in bow:
            self.wordDict[word] += 1

        # just showing the correctness of this part of function
        # pd.DataFrame(wordDict)

        # computing TF
        tfDict = {}
        nbowCount = len(bow)

        for word, count in self.wordDict.items():
            tfDict[word] = count / nbowCount

        # computing IDF
        idfDict = dict.fromkeys(self.wordDict, 0)
        for word, count in self.wordDict.items():
            if count > 0:
                idfDict[word] += 1
        for word, ni in idfDict.items():
            idfDict[word] = math.log10((3)/(ni + 1))

        # computing TF-IDF
        for word, tfval in tfDict.items():
            self.tfidf[word] = tfval * idfDict[word]
        # just showing the correctness of this part of function
        # pd.DataFrame(tfidf)

    def cosineSimilarity(self, vec1, vec2):
        return np.dot(vec1, vec2.T) / (np.sqrt(np.sum(vec1 ** 2)) * np.sqrt(np.sum(vec2 ** 2)))

    def computeSentenceEach(self, question):
        question_tfidf = np.zeros(len(self.wordDict))
        for word in question.strip().split(' '):
            if word not in self.wordDict or self.wordDict[word] not in self.tfidf:
                continue
            question_tfidf[self.wordDict[word]] = self.tfidf[self.wordDict[word]]
        return question_tfidf

    def find_sentence(self, question, article):
        """
            TODO: find the sentence in article
                ideas: using tf-idf, cosine similarity... 
        """
        que = []
        query_tfidf = self.computeSentenceEach(question.lower())
        for i, vec in enumerate(self.tfidf):
            result = self.cosineSimilarity(float(vec), query_tfidf)
            que.append([-1 * result, i])
        que.sort(key = lambda x:x[0])
        return np.array[0]
        # return "Dempsey was born in Nacogdoches, Texas, and, for much of his childhood, his family lived in a trailer park, where he and his siblings grew up playing soccer with Hispanic immigrants. In his teens, Dempsey maintained these ties playing in a local Mexican-dominated adult league. Dempsey is of Irish descent on his father's side. His older brother Ryan was offered a tryout for the Dallas Texans, an elite youth soccer club, and brought Clint, who was noticed and recruited while passing time juggling a ball on the sidelines. Dempsey became a standout on the team at an early age but had to quit due to his family's time and money constraints as his eldest sister Jennifer was becoming a ranked youth tennis player. Several parents of his teammates with the Texans offered to assist the Dempseys with expenses and travel, allowing him to rejoin the club."
    
    def classify_and_answer(self, question, sentence):
        """
            TODO: classify question into different types using leading word
            then process the sentence using libraries

                Binary: Is/are/was/were/did/do/does/has/had/have...
                    - 我们可以先用随机来回答binary问题，后面再进一步改动
            --------------
                Who/Whom    NER Person
                When        NER Date
                Where       NER Location
            ---------------
                What/Which
                    - is/are..  
                    - else      
                How
                    - is/are..  
                    - many/much
                    - else      
                Why
        """
        stanza = StanzaProcessor(sentence=sentence).process()

        processed_sentence = stanza.sentences[0]
        processed_sentence = stanza.sentences
        matched = []
        stanza = StanzaProcessor(sentence=question).process()
        processed_question = stanza.sentences[0]
        
        question_word = set([w.text for w in processed_question.words])

        for s in processed_sentence:
            
            matched.append([sum([c.text in question_word for c in s.words]),s.text])

        matched.sort(reverse=True)
        real_sentence = matched[0][1]
        
        
        n = len(processed_sentence)

        first_word = processed_question.words[0].text.lower()
        import random
        if first_word not in ["what", "when", "who", "where", "why"]:
            return random.choice(["Yes, ", "No, "]) + real_sentence
        else:
            return real_sentence
            
        if first_word == 'what' or first_word == 'which':
            return HowWhatWhyAnswer(processed_sentence, processed_question).what()
        elif first_word == 'how':
            return HowWhatWhyAnswer(processed_sentence, processed_question).how()
        elif first_word == 'why':
            return HowWhatWhyAnswer(processed_sentence, processed_question).why()
        elif first_word == 'who' or first_word == 'whom':
            return WhoWhenWhereAnswer(processed_sentence, processed_question).who()
        elif first_word == 'when':
            return WhoWhenWhereAnswer(processed_sentence, processed_question).when()
        elif first_word == 'where':
            return WhoWhenWhereAnswer(processed_sentence, processed_question).where()
        else:
            generate = YesNoAnswer(processed_sentence, processed_question)
            return generate.yesno()
    
    def generate(self):
        #self.calculate_tfidf(self.article)

        for question in self.questions:
            
            #sentence = self.find_sentence(question, self.article)
            answer = self.classify_and_answer(question, self.article)
            self.answers.append(answer)

            # for testing
            print(answer)

    

if __name__ == "__main__":
    article = sys.argv[1]
    question_file = sys.argv[2]
    questions = []
    with open(question_file, 'r') as f:
        count = 0
        for line in f:
            count += 1
            line = line.replace("?", "") # delete question mark
            questions.append(line.strip())
    answer = Answer(article, questions)
    answer.generate()
