1. Sentence Segmentation:  ['Elon Musk.', 'Carnegie Mellon University?', 'Guangdong:"ok".']
2. Word Tokenization:  [['Elon', 'Musk', '.'], ['Carnegie', 'Mellon', 'University', '?'], ['Guangdong', ':', "''", 'ok', "''", '.']]
3. POS:  [[('Elon', 'NNP'), ('Musk', 'NNP'), ('.', '.')], [('Carnegie', 'NNP'), ('Mellon', 'NNP'), ('University', 'NNP'), ('?', '.')], [('Guangdong', 'NN'), (':', ':'), ("''", "''"), ('ok', 'NN'), ("''", "''"), ('.', '.')]]
4. NER: 
[('Elon', 'NNP', 'B-PERSON'), ('Musk', 'NNP', 'B-ORGANIZATION'), ('.', '.', 'O')]
[('Carnegie', 'NNP', 'B-PERSON'), ('Mellon', 'NNP', 'B-PERSON'), ('University', 'NNP', 'I-PERSON'), ('?', '.', 'O')]
[('Guangdong', 'NN', 'B-GPE'), (':', ':', 'O'), ("''", "''", 'O'), ('ok', 'NN', 'O'), ("''", "''", 'O'), ('.', '.', 'O')]
